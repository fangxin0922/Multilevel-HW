---
title: 'Problem Set 6: Longitudinal wtsa and Three-Level Models'
author: "S-043 (Fall 2023)"
wtse: 'Template'
header-includes:
output: pdf_document
---
```{r setup, echo=FALSE, message=FALSE, warning=FALSE}
# libraries
library(tidyverse)
library(lme4)
library(lmerTest)
library(arm)
library(knitr)
library(texreg)
library(stargazer)
library(haven)

opts_chunk$set(message=FALSE, warning=FALSE, echo = TRUE, out.width="4.5in")
options(dplyr.summarise.inform = FALSE, digits = 3)

# set ggplot theme
theme_set(theme_classic())

# clear memory
rm(list = ls())
## You can use this block if you want to do your wtsa cleaning in your Markdown file. You are also welcome to do your wtsa cleaning in an entirely separate script. 
# Loading the wtsa
wts <- read_dta("/Users/Betty/Desktop/Fall 2023/Multilevel-HW/PS 6 /childweights.dta")
```

# Linear and Quadratic Growth Models

## 1a. Plot

No need to turn in anything here.

## 1b. Fit a Linear Growth Model to these Data

```{r}
##center the data
wts$age_center = wts$age - mean(wts$age)

m1 <- lmer(weight ~ age_center + gender + (1 + age_center |id), data = wts)

summary(m1)
```

## 1c. Fit a Quadratic Growth Model

The model fails because the number of observations is less than the number of random effect parameters. By review of the histogram we can visualize the distribution of number of observations per child, the majority of children have 3 or 4 observations, but some have 5 and some have as few as 1 or 2. 

```{r}
##squared term
wts$age_sq = wts$age_center^2

#the model below will not run
#m2 <- lmer(weight ~ age_center + age_sq + gender + (1 + age_center + age_sq|id), data = wts)

table(wts$id) # tally up obs/child
table(table(wts$id)) # tally the tallys
# Add number of obs for each group to your data.
wts = wts %>% group_by(id) %>%
mutate(n = n())

hist(wts$n)
```

## 1d. Subset the Data to fit the Quadratic Model

We have subset the data to remove students who had only 1 observation, this allowed the quadratic model to converge. In terms of data loss, 4 participants (each with 1 observation so 4 unique observations), were removed. 

```{r}
subset <- filter(wts, n != 1)

subset$age_center = subset$age - mean(subset$age)
subset$age_sq = subset$age_center^2

m3 <- lmer(weight ~ age_center + age_sq + gender + (1 + age_center + age_sq|id), data = subset)

summary(m3)

```

## 1e. Linear vs. Quadratic
For the first comparison, we will work on the same subset dataset for both models (where those with only one observation were removed).

Using a likelihood ratio test (calculated through ANOVA), we find that the quadratic model is a better fit for the data.

We also want to test whether the linear model including all the data (so not subset to omit those with only 1 observation), is a better fit than the quadratic model. Per the R2, the quadratic model is a better fit (0.976 vs 0.856); however, R2 nearly always increases with a more complex model, and the slight increase in R2 may not be worth the loss of data from 4 students. 

```{r}
# linear model on subset data
m1_subset <- lmer(weight ~ age_center + gender + (1 + age_center|id), data = subset)
summary(m1_subset)

## quadratic model again on subset data (same as q1d)
m3 <- lmer(weight ~ age_center + age_sq + gender + (1 + age_center + age_sq|id), data = subset)
summary(m3)

anova(m1_subset, m3)

### now test our original linear growth model with ALL the data
m1 <- lmer(weight ~ age_center + gender + (1 + age_center |id), data = wts)
summary(m1)

##compare it to our quadratic model. We can't use LRT because the datasets are different. We will use R2
# install.packages("MuMIn")
library(MuMIn)

r.squaredGLMM(m1)
r.squaredGLMM(m3)

```

## 1f. Plot the Growth Curves

```{r}
library(ggplot2)

selected_ids <- sample(subset$id, 16)

# Filter the dataset to include only the selected children
selected_wts <- subset[subset$id %in% selected_ids, ]

ggplot(data = selected_wts, aes(x = age, y = weight, group = id, color = factor(gender))) +
  facet_wrap(~ id) +
  geom_point() +
  geom_line(aes(y = predict(m3, newdata = selected_wts), color = factor(gender)), linetype = "dashed") + geom_line(aes(y = predict(m1_subset, newdata = selected_wts), color = factor(gender))) +
 labs(title = "Child weight growth over time",
x = "Age (months)",
y = "Predicted weight",
caption = "Age is centered at 1.08 years. 
Dashed lines are for the quadratic growth model and solid lines are for linear growth model") +
theme(axis.text.x = element_text(size = rel(.75), angle = 00))
```

\newpage

# Piecewise Linear Growth (READS wtsa)

## 2a. Mathematical Model


$$
\begin{aligned}
score_{tjk} &= \beta_{0jk} + \beta_{1jk} school_{tjk} + \beta_{2jk} summer_{tjk} + \varepsilon_{tjk} \\
\beta_{0jk} &= \gamma_{00k} + \mu_{0jk} \\
\beta_{1jk} &= \gamma_{10k} + \mu_{1jk} \\
\beta_{2jk} &= \gamma_{20k} + \mu_{2jk} \\
\gamma_{00k} &= \alpha_{000} + \nu_{0k} \\
\gamma_{10k} &= \alpha_{100} + \nu_{1k}\\
\gamma_{20k} &= \alpha_{200} + \nu_{2k}
\end{aligned}
$$
where $t$ is time $j$ is a given student and $k$ is a given school

where $score_{ijk}$ is the score for the $jth$ student in the $kth$ school at the $t$ time point. 

$\beta_{0jk}$ and $\beta_{1jk}$ and $beta_2{jk}$ is the grand intercept or average across all schools, as well as the average  learning rate during school months and for summer months respectively. 

$\varepsilon_{ijk}$ represents the (within-person) residual error at the individual observation level.

$\mu_{0jk}$ and $\mu_{1jk}$ and $\mu_{2jk}$ represent random effects at the student level, or how student $j$ differs from the average student in school $k$. 

$\gamma_{00k}$ and $\gamma_{10k}$ and $\gamma_{20k}$  represent average student intercept and growth rates (for school months and summer months respectively) in school $k$.

$\nu_{0k}$ and $\nu_{1k}$ and $\nu_{2k}$  represent random effects at the school level or rather how school $k$ differs from the average school with respect to the random intercept of the school, or random effect of school and summer months on learning rates respectively. 

## 2b. Answer RQ1: Do students learn more quickly over the summer or school year? 

```{r}
studs <- readRDS("~/Desktop/Fall 2023/Multilevel-HW/PS 6 /READS_student_data.Rds")

studs$sum2=studs$summer-studs$school


m2 <- lmer(score ~ 1 + sum2 + (1+sum2|id) + (1+sum2|sch), data = studs)
display(m2)
confint(m2)
```
The model predicts an increase of 0.19 units in the 'score' outcome variable for a one unit increase in summer months to the baseline learning growth rate. This is statistically significant with a 95% CI of [-1.82, -1.60] that does not contain the null value. 

The level 1 model for this lmer code is $$score_{tjk}=\beta_{0jk}+\beta_{1jk}*summer_{tjk}+\varepsilon_{tjk}$$
where summer is summer months minus school months. 

## 2c. Answer RQ2: Do student's rates of growth depend on student level poverty?

```{r}
m_3 <- lmer(score ~ 1 + sum2*frl + (1 + sum2|id) + (1 + sum2*frl|sch),
                   data = studs)
display(m_3)

```

Note that we are assuming that free and reduced lunch eligibility for a student j may vary in across schools, but not within schools (as indicated by the inclusion of free or reduced lunch variable into random slope for schools but NOT for individuals)

The positive value of 0.37 means that there is between school variability in the interaction effect between free and reduced lunch and the effect of summer (months) on the learning scores for students In other words, the influence of the interaction between free or reduced lunch eligibility (frl) and the difference variable summer 2 on student scores differs across schools. This difference is above what is explained by the fixed effects interaction in the model, as well as the fixed effects of frl and summer months (time) in the variation of student scores.  


## 2d. Concept Check 1

It would be theoretically possible but we would run into several issues with this more complex model that may be unnecessary.
We would more than likely have issues with multidisciplinary in the model, given the imbalance between some schools having free or reduced lunch eligibility for ALL of their students and some schools not having any students who are not eligible reducing the stability of our model, and leading to loss of precision potentially. With respect to modeling a random slope which is intent on showcasing the variability between schools (i.e how much different a school is from another school, and how this variability impacts the outcome of student reading scores leading to potential convergence issues as we do not have enough observations to estimate meaningful random effects within the higher unit (school level).   